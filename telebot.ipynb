{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4kRo42h5B18k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5271e758-42b0-4f92-be0f-7a5425dbaa34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyTelegramBotAPI in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pyTelegramBotAPI) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pyTelegramBotAPI) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pyTelegramBotAPI) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pyTelegramBotAPI) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pyTelegramBotAPI) (1.24.3)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.63.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.10.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.21.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.63.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Requirement already satisfied: stop-words in /usr/local/lib/python3.7/dist-packages (2018.7.23)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyTelegramBotAPI\n",
        "\n",
        "import telebot\n",
        "from telebot import types\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, Embedding\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import one_hot\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize, pos_tag\n",
        "\n",
        "from string import punctuation\n",
        "import re\n",
        "\n",
        "\n",
        "import sys\n",
        "!{sys.executable} -m pip install spacy\n",
        "!{sys.executable} -m spacy download en\n",
        "\n",
        "import spacy\n",
        "\n",
        "!pip install stop-words\n",
        "from stop_words import get_stop_words\n",
        "\n",
        "from textblob import TextBlob\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import json\n",
        "from urllib.parse import urlparse\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bot = telebot.TeleBot('5260450850:AAGkp80bHug3CzO0AVj41IEoVNDocOJLfGk');"
      ],
      "metadata": {
        "id": "OHBF5Pk8vgSa"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parser(link):\n",
        "    #link='https://www.foxnews.com/politics/walt-disney-would-be-rolling-over-in-his-grave-over-companys-wokeness-florida-park-goer-says'\n",
        "    req = requests.get(link).text\n",
        "    soup = BeautifulSoup(req, \"lxml\")\n",
        "    head = soup.find('head')\n",
        "    zagolovok = head.find('title').text\n",
        "    textp = soup.find_all('div', attrs={'class': \"article__text\"})\n",
        "    if (len(textp)) == 0:\n",
        "        textp = soup.find_all('span', attrs={'class': 'intro'})\n",
        "    if (len(textp)) == 0:\n",
        "        text = soup.find_all('span', attrs={'class': 'intro'})\n",
        "    if (len(textp)) == 0:\n",
        "        textp = soup.find_all('p')\n",
        "    \n",
        "    # domain = urlparse(link).netloc\n",
        "    # if (int(domain.find(\"www.\")) != -1):\n",
        "    #   domain = domain[4:]\n",
        "    # url = link.split(\"//\")[-1].split(\"/\")[0].split('?')[0]\n",
        "    # show = \"https://input.payapi.io/v1/api/fraud/domain/age/\" + domain\n",
        "    # r = requests.get(show, verify = False)\n",
        "    # soupp = BeautifulSoup(r.text, \"lxml\")\n",
        "    # if requests.get(link).status_code ==200:\n",
        "    #     age = soupp.find('body').text\n",
        "    #     str = int(age.find(\"Reg\"))\n",
        "    #     end = int(age.find(\"}\"))\n",
        "    #     # print(age[str:(end - 1)])\n",
        "    #     age=age[str:(end - 1)]\n",
        "    #     data = r.text\n",
        "    #     jsonToPython = json.loads(data)\n",
        "    # else:\n",
        "    #   age=np.nan\n",
        "\n",
        "    for j in range(len(textp)):\n",
        "      textp[j]=textp[j].text\n",
        "\n",
        "    textp=''.join(textp)\n",
        "    zagolovok=''.join(zagolovok)\n",
        "\n",
        "    return textp, zagolovok\n",
        "    "
      ],
      "metadata": {
        "id": "76sM8ReC0UXM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "paqwcWcF0eEg",
        "outputId": "3941dfde-3a97-49a2-81da-60c9d2b91b1c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-674d2322-942a-408d-82ea-957e1bca2cdf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-674d2322-942a-408d-82ea-957e1bca2cdf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving итоговая модель.h5 to итоговая модель.h5\n",
            "Saving модель_для_анализа_заголовка.h5 to модель_для_анализа_заголовка.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# анализ заголовка\n",
        "def headlineAnalis(headline):\n",
        "    model_for_headline = keras.models.load_model('модель_для_анализа_заголовка.h5')\n",
        "\n",
        "    df_h = pd.DataFrame({'Headline' : [headline]})\n",
        "\n",
        "    oh_headlines = [one_hot(words, 5000) for words in df_h['Headline']]\n",
        "    x = pad_sequences(oh_headlines, padding='pre', maxlen=30)\n",
        "\n",
        "    headLines = model_for_headline.predict(x)\n",
        "    df_h.Headline = headLines\n",
        "\n",
        "    return df_h"
      ],
      "metadata": {
        "id": "81Fs1NlM0xWY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# удаление пунктуации и привеение к нижнему регистру\n",
        "\n",
        "def remove_punct(text):\n",
        "    table = {33: ' ', 34: ' ', 35: ' ', 36: ' ', 37: ' ', 38: ' ', 39: ' ', 40: ' ', 41: ' ', 42: ' ',\n",
        "             43: ' ', 44: ' ', 45: ' ', 46: ' ', 47: ' ', 58: ' ', 59: ' ', 60: ' ', 61: ' ', 62: ' ',\n",
        "             63: ' ', 64: ' ', 91: ' ', 92: ' ', 93: ' ', 94: ' ', 95: ' ', 96: ' ', 123: ' ', 124: ' ', 125: ' ', 126: ' '}\n",
        "    return text.translate(table)\n",
        "\n",
        "def cleanText(text):\n",
        "    text = text.lower()\n",
        "    \n",
        "    text = remove_punct(text)\n",
        "\n",
        "    signs = ['?', ',', ':', '!', '.', ';', '«', '»', '(', ')', '*', '+', '-', '^', '|', '=', \"’\", \"‘\",  '”', '—', '@', '>', '<', '–', '&', '%', '•', '/', '“']\n",
        "    for punct_sign in signs:\n",
        "        text = text.replace(punct_sign, ' ')\n",
        "\n",
        "    text = text.replace('\\n', '')\n",
        "    text = text.replace('\\r', '')\n",
        "    text = re.sub(r\"\\d+\", \"\", text, flags=re.UNICODE)\n",
        "    text = text.replace(\"  \" , \" \")\n",
        "    text = text.replace(\"  \" , \" \")\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "oNFjFfnZ00KN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# подсчет количества наречий\n",
        "\n",
        "def amountAdverbs(text):\n",
        "    amountADV = 0\n",
        "    tokens = word_tokenize(text)\n",
        "    tags = pos_tag(tokens)\n",
        "    for i in tags:\n",
        "        if len(i) == 2:\n",
        "            if i[1] == 'RB':\n",
        "                amountADV += 1\n",
        "        else:\n",
        "            continue\n",
        "    return amountADV"
      ],
      "metadata": {
        "id": "nZT660zH03g2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# лемматизация и удаление стоп-слов\n",
        "\n",
        "def removeStopWords_and_lemmitizeText(text):\n",
        "    lemmatizer = spacy.load('en', disable=['parser', 'ner'])\n",
        "    doc = lemmatizer(text)\n",
        "    new_text = \" \".join([token.lemma_ for token in doc\\\n",
        "                         if token.lemma_ not in get_stop_words('english')\\\n",
        "                         and (token.lemma_ != \"-PRON-\")\\\n",
        "                         and (len(token.lemma_) != 1 or token.lemma_ == 'i')])\n",
        "    # new_text = new_text.replace(\"-PRON-\", '')\n",
        "    # new_text = new_text.replace(\"s\", '')\n",
        "    return new_text"
      ],
      "metadata": {
        "id": "Oc6DTpxM06d-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# тональность и субъективность\n",
        "\n",
        "def polarityAndSubjectivityOfText(text):\n",
        "    pol = TextBlob(text).polarity\n",
        "    sub = TextBlob(text).subjectivity\n",
        "    return pol, sub"
      ],
      "metadata": {
        "id": "2eQS4lQo09OX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# векторизация\n",
        "\n",
        "def toVecText(text):\n",
        "\n",
        "    d = {'text': [text]}\n",
        "    df1 = pd.DataFrame(d)\n",
        "\n",
        "    oh_text = [one_hot(words, 5000) for words in df1.text]\n",
        "    embedded_doc = pad_sequences(oh_text, padding='pre', maxlen=800)\n",
        "    df_text = pd.DataFrame(embedded_doc)\n",
        "\n",
        "    return df_text\n",
        "\n",
        "# oh_text = one_hot(text, 5000)\n",
        "# embedded_doc = pad_sequences(oh_text, padding='pre', maxlen=800)\n",
        "# df_text = pd.DataFrame(embedded_doc)\n",
        "# df_new = pd.concat([df.drop(['Body_02'], axis = 1), df_text], axis = 1)"
      ],
      "metadata": {
        "id": "zBprUuQq1AFV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from numpy.ma.core import logical_not\n",
        "def allTextPreparation(text):\n",
        "\n",
        "    # чистим от пунктуации + нижгий регистр\n",
        "    text = cleanText(text)\n",
        "\n",
        "    # считаем количество наречий\n",
        "    amountAdv = amountAdverbs(text)\n",
        "\n",
        "    # лемматизация и удаление стоп-слов\n",
        "    text = removeStopWords_and_lemmitizeText(text)\n",
        "\n",
        "    # полярность и субъективность\n",
        "    l_pol_sub = polarityAndSubjectivityOfText(text)\n",
        "\n",
        "    polarity = l_pol_sub[0]\n",
        "    subjectivity = l_pol_sub[1]\n",
        "\n",
        "    # векторизация текста\n",
        "    vec_text = toVecText(text)\n",
        "\n",
        "    data_ = {'Amount Adverbs' : [amountAdv], \n",
        "             'Polarity' : [polarity],\n",
        "             'Subjectivity' : [subjectivity]}\n",
        "\n",
        "    df_features = pd.DataFrame(data_)\n",
        "\n",
        "    df_new = pd.concat([df_features, vec_text], axis = 1)\n",
        "\n",
        "    return df_new\n"
      ],
      "metadata": {
        "id": "h5ey7yf31CFb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataPreparation(data):\n",
        "    # data = [text, headline]\n",
        "    text = data[0]\n",
        "    headline = data[1]\n",
        "    df_text = allTextPreparation(text)\n",
        "    df_headline = headlineAnalis(headline)\n",
        "\n",
        "    df = pd.concat([df_headline, df_text], axis = 1)\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "6AY5yNPa1E7O"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataPrediction(data_df):\n",
        "    finalModel = keras.models.load_model('итоговая модель.h5')\n",
        "    result = finalModel.predict(data_df)\n",
        "    result = int(np.around(result))\n",
        "\n",
        "    if result == 0:\n",
        "        return \"С высокой долей вероятности новость - фейк.\"\n",
        "    elif result == 1:\n",
        "        return \"С высокой долей вероятности новость не является фейком.\"\n",
        "    "
      ],
      "metadata": {
        "id": "ECw2dlAv1Hev"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fakeNewsChecking(url):\n",
        "    # отправляем url в парсер, получаем данные\n",
        "    data = parser(url)\n",
        "    df = dataPreparation(data)\n",
        "    res = dataPrediction(df)\n",
        "    return res"
      ],
      "metadata": {
        "id": "x5z13vEZ1Lf4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "c9CeBpsyC8_L"
      },
      "outputs": [],
      "source": [
        "\n",
        "@bot.message_handler(commands=[\"start\", \"restart\"])\n",
        "def start(m, res=False):\n",
        "        bot.send_message(m.chat.id, 'Привет, пользователь!\\n\\nМеня зовут FakeBot. Я защищу тебя от фейков в сети. Для этого мне лишь потребуется ссылка на подозрительную новость, нуждающуюся в проверке.\\n\\nСписок команд:\\\n",
        "        \\n/restart – перезапустить ботa\\\n",
        "        \\n/help – показать гид по командам\\\n",
        "        \\n/check – проверить новость\\\n",
        "        \\n/more – узнать больше обо мне и моих создателях')\n",
        "@bot.message_handler(commands=[\"help\"])\n",
        "def help(message):\n",
        "  bot.send_message(message.from_user.id, 'Список команд:\\\n",
        "  \\n/restart – перезапустить ботa\\\n",
        "  \\n/help – показать гид по командам\\\n",
        "  \\n/check – проверить новость\\\n",
        "  \\n/more – узнать больше обо мне и моих создателях')\n",
        "# @bot.message_handler(commands=[\"start\"])\n",
        "# def start(m, res=False):\n",
        "#         markup=types.ReplyKeyboardMarkup(resize_keyboard=True)\n",
        "#         item1=types.KeyboardButton(\"Начать\")\n",
        "#         item2=types.KeyboardButton(\"Информация\")\n",
        "#         item3=types.KeyboardButton(\"Помощь\")\n",
        "#         markup.add(item1)\n",
        "#         markup.add(item2)\n",
        "#         markup.add(item3)\n",
        "#         bot.send_message(m.chat.id, 'Нажми: \\nНачать(чтобы воспользоваться программой)\\nИнформация(чтобы узанть о нас)\\nПомощь(чтобы узнать о боте)',  reply_markup=markup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "OqBOetzpBl2R"
      },
      "outputs": [],
      "source": [
        "@bot.message_handler(commands=[\"more\"])\n",
        "def help(message):\n",
        "  bot.send_message(message.from_user.id, 'Меня разработала пара ребят, разработчиков-любителей, из лицея 1511 при МИФИ в городе Москве. Они очень старались и надеются, что этот бот будет тебе полезен. 😊')\n",
        "@bot.message_handler(commands=\"check\")\n",
        "def rabota(message):\n",
        "  bot.send_message(message.from_user.id, 'Введи ссылку на новость')\n",
        "  bot.register_next_step_handler(message, test);\n",
        "def test(message):\n",
        "  link=message.text\n",
        "  if requests.get(link).status_code==200:\n",
        "    link=message.text\n",
        "    bot.send_message(message.chat.id, 'Подожди несколько секунд, идут сложные вычисления...')\n",
        "    predict=fakeNewsChecking(link)\n",
        "    bot.send_message(message.chat.id,text=predict)\n",
        "  else:\n",
        "    bot.send_message(message.chat.id,'C этой ссылкой что-то не так. Возможно, сайт не отвечает, или страница больше не существует.')\n",
        "\n",
        "# @bot.message_handler(func=lambda message: message.text=='Начать')\n",
        "# def rabota(message):\n",
        "#   bot.send_message(message.from_user.id, 'Введите ссылку на новость')\n",
        "#   bot.register_next_step_handler(message, test);\n",
        "# def test(message):\n",
        "#     bot.send_message(message.chat.id, 'Подожди несколько секунд, идут сложные вычисления...')\n",
        "#     link=message.text\n",
        "#     predict=fakeNewsChecking(link)\n",
        "#     bot.send_message(message.chat.id,text=predict)\n",
        "# def proga(m):\n",
        "#   bot.send_message(m.from_user.id, 'ссылка обрабатывается')\n",
        "# @bot.message_handler(func=lambda message: message.text=='Информация')\n",
        "# def info(message):\n",
        "#   bot.send_message(message.from_user.id, \"Это проект учащихся IT-класса лицея №1511 при МИФИ, созданный для защиты от фейковых новостей в сети.\")\n",
        "# @bot.message_handler(func=lambda message: message.text=='Помощь')\n",
        "# def help(message):\n",
        "#   bot.send_message(message.from_user.id, \"Если у вас есть вопросы по боту или работе программы, то задать их можно здесь @miCherex\")\n",
        "\n",
        "bot.polling() "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jtJS8uVs-LbM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "telebot.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}