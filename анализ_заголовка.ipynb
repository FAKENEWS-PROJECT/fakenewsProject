{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "анализ заголовка.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjlabXYyHatO"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential\n",
        "model = Sequential()\n",
        "\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range = (0,1))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "5X7ipi2wHgEX",
        "outputId": "c1c64f52-f69f-4343-8485-1e7c2f95d89c"
      },
      "source": [
        "from google.colab import files\n",
        "upload = files.upload()"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dbec4453-1d2b-4ea6-bb00-71adcb509c3b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dbec4453-1d2b-4ea6-bb00-71adcb509c3b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data.csv to data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CLJSvcXN457"
      },
      "source": [
        "# fake = pd.read_csv(\"Fake.csv\")\n",
        "# true = pd.read_csv(\"True.csv\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uKrbUDLPUgJ"
      },
      "source": [
        "# fake['true'] = 0\n",
        "# true['true'] = 1\n",
        "\n",
        "# df = pd.concat([fake, true], axis = 0)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "NqX7pDBCELI6",
        "outputId": "571a062d-b0dd-4a6f-9ba6-63a9753eea5c"
      },
      "source": [
        "df = pd.read_csv('data.csv')\n",
        "df"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URLs</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Body</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://www.bbc.com/news/world-us-canada-414191...</td>\n",
              "      <td>Four ways Bob Corker skewered Donald Trump</td>\n",
              "      <td>Image copyright Getty Images\\nOn Sunday mornin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.reuters.com/article/us-filmfestiva...</td>\n",
              "      <td>Linklater's war veteran comedy speaks to moder...</td>\n",
              "      <td>LONDON (Reuters) - “Last Flag Flying”, a comed...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.nytimes.com/2017/10/09/us/politics...</td>\n",
              "      <td>Trump’s Fight With Corker Jeopardizes His Legi...</td>\n",
              "      <td>The feud broke into public view last week when...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.reuters.com/article/us-mexico-oil-...</td>\n",
              "      <td>Egypt's Cheiron wins tie-up with Pemex for Mex...</td>\n",
              "      <td>MEXICO CITY (Reuters) - Egypt’s Cheiron Holdin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>http://www.cnn.com/videos/cnnmoney/2017/10/08/...</td>\n",
              "      <td>Jason Aldean opens 'SNL' with Vegas tribute</td>\n",
              "      <td>Country singer Jason Aldean, who was performin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4004</th>\n",
              "      <td>http://beforeitsnews.com/sports/2017/09/trends...</td>\n",
              "      <td>Trends to Watch</td>\n",
              "      <td>Trends to Watch\\n% of readers think this story...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4005</th>\n",
              "      <td>http://beforeitsnews.com/u-s-politics/2017/10/...</td>\n",
              "      <td>Trump Jr. Is Soon To Give A 30-Minute Speech F...</td>\n",
              "      <td>Trump Jr. Is Soon To Give A 30-Minute Speech F...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4006</th>\n",
              "      <td>https://www.activistpost.com/2017/09/ron-paul-...</td>\n",
              "      <td>Ron Paul on Trump, Anarchism &amp; the AltRight</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4007</th>\n",
              "      <td>https://www.reuters.com/article/us-china-pharm...</td>\n",
              "      <td>China to accept overseas trial data in bid to ...</td>\n",
              "      <td>SHANGHAI (Reuters) - China said it plans to ac...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4008</th>\n",
              "      <td>http://beforeitsnews.com/u-s-politics/2017/10/...</td>\n",
              "      <td>Vice President Mike Pence Leaves NFL Game Beca...</td>\n",
              "      <td>Vice President Mike Pence Leaves NFL Game Beca...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4009 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   URLs  ... Label\n",
              "0     http://www.bbc.com/news/world-us-canada-414191...  ...     1\n",
              "1     https://www.reuters.com/article/us-filmfestiva...  ...     1\n",
              "2     https://www.nytimes.com/2017/10/09/us/politics...  ...     1\n",
              "3     https://www.reuters.com/article/us-mexico-oil-...  ...     1\n",
              "4     http://www.cnn.com/videos/cnnmoney/2017/10/08/...  ...     1\n",
              "...                                                 ...  ...   ...\n",
              "4004  http://beforeitsnews.com/sports/2017/09/trends...  ...     0\n",
              "4005  http://beforeitsnews.com/u-s-politics/2017/10/...  ...     0\n",
              "4006  https://www.activistpost.com/2017/09/ron-paul-...  ...     0\n",
              "4007  https://www.reuters.com/article/us-china-pharm...  ...     1\n",
              "4008  http://beforeitsnews.com/u-s-politics/2017/10/...  ...     0\n",
              "\n",
              "[4009 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3Ed5c67RlUH"
      },
      "source": [
        "def create_num(x):\n",
        "    text = []\n",
        "\n",
        "    for i in range(len(x)):\n",
        "        text.append(x[i].split())\n",
        "\n",
        "    text = pd.DataFrame(text)\n",
        "\n",
        "    text = text.stack().rank().unstack()\n",
        "    text = text.fillna(-1)\n",
        "    \n",
        "    text = scaler.fit_transform(text)\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7RNtfLcrrN1",
        "outputId": "1a8f2f39-2b88-436e-8843-fb929dfcbb61"
      },
      "source": [
        "# text = pd.Series(\"Texan (36) suddenly forgets 20 years of his life\")\n",
        "# inpt = pd.concat([df['title'], text])\n",
        "\n",
        "\n",
        "x = pd.DataFrame(create_num(df['Headline'].values))\n",
        "y = np.array(df['Label'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=1/3, random_state=42)\n",
        "\n",
        "# x = np.delete(x, (x.shape[0]-1), axis = 0)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(x, y[:-1], test_size=1/3, random_state=42)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2672, 110)\n",
            "(2672,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcwg_lhTZWd2",
        "outputId": "a68291af-cd3a-451b-a743-5190367ca2ae"
      },
      "source": [
        "model.add(Dense(500))\n",
        "model.add(Dropout(0.275))\n",
        "model.add(Dense(250, activation = 'relu'))\n",
        "model.add(Dropout(0.275))\n",
        "model.add(Dense(125, activation = 'relu'))\n",
        "model.add(Dropout(0.275))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(loss = 'huber_loss',\n",
        "             optimizer = 'adam',\n",
        "             metrics = 'accuracy')\n",
        "\n",
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=1024,\n",
        "    epochs=100,\n",
        "    validation_split=0.2,\n",
        "    shuffle= True)"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 1s 143ms/step - loss: 0.1217 - accuracy: 0.5077 - val_loss: 0.1128 - val_accuracy: 0.5738\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.1120 - accuracy: 0.5915 - val_loss: 0.1068 - val_accuracy: 0.6579\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.1039 - accuracy: 0.6996 - val_loss: 0.1027 - val_accuracy: 0.6692\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0984 - accuracy: 0.6926 - val_loss: 0.1002 - val_accuracy: 0.6860\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0951 - accuracy: 0.7169 - val_loss: 0.0985 - val_accuracy: 0.6860\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0903 - accuracy: 0.7323 - val_loss: 0.0958 - val_accuracy: 0.7047\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0871 - accuracy: 0.7412 - val_loss: 0.0946 - val_accuracy: 0.7103\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0846 - accuracy: 0.7590 - val_loss: 0.0914 - val_accuracy: 0.7271\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0832 - accuracy: 0.7585 - val_loss: 0.0886 - val_accuracy: 0.7458\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0811 - accuracy: 0.7651 - val_loss: 0.0881 - val_accuracy: 0.7477\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0827 - accuracy: 0.7777 - val_loss: 0.0838 - val_accuracy: 0.7664\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0792 - accuracy: 0.7810 - val_loss: 0.0840 - val_accuracy: 0.7458\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0783 - accuracy: 0.7777 - val_loss: 0.0821 - val_accuracy: 0.7776\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0771 - accuracy: 0.7899 - val_loss: 0.0815 - val_accuracy: 0.7776\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0748 - accuracy: 0.7969 - val_loss: 0.0793 - val_accuracy: 0.7682\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0752 - accuracy: 0.7890 - val_loss: 0.0776 - val_accuracy: 0.7794\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0720 - accuracy: 0.8063 - val_loss: 0.0806 - val_accuracy: 0.7757\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0734 - accuracy: 0.7978 - val_loss: 0.0769 - val_accuracy: 0.7832\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0722 - accuracy: 0.7988 - val_loss: 0.0788 - val_accuracy: 0.7720\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0719 - accuracy: 0.7974 - val_loss: 0.0772 - val_accuracy: 0.7832\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0706 - accuracy: 0.8058 - val_loss: 0.0764 - val_accuracy: 0.7813\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0679 - accuracy: 0.8170 - val_loss: 0.0757 - val_accuracy: 0.7757\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0698 - accuracy: 0.8077 - val_loss: 0.0755 - val_accuracy: 0.7682\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0688 - accuracy: 0.8128 - val_loss: 0.0753 - val_accuracy: 0.7664\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0687 - accuracy: 0.8184 - val_loss: 0.0742 - val_accuracy: 0.7645\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0684 - accuracy: 0.8138 - val_loss: 0.0735 - val_accuracy: 0.7925\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0680 - accuracy: 0.8170 - val_loss: 0.0719 - val_accuracy: 0.7888\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0673 - accuracy: 0.8161 - val_loss: 0.0725 - val_accuracy: 0.7925\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0680 - accuracy: 0.8152 - val_loss: 0.0715 - val_accuracy: 0.7832\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0668 - accuracy: 0.8147 - val_loss: 0.0721 - val_accuracy: 0.7776\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0663 - accuracy: 0.8194 - val_loss: 0.0728 - val_accuracy: 0.7757\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0667 - accuracy: 0.8184 - val_loss: 0.0712 - val_accuracy: 0.7738\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0659 - accuracy: 0.8198 - val_loss: 0.0700 - val_accuracy: 0.8056\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0656 - accuracy: 0.8278 - val_loss: 0.0696 - val_accuracy: 0.8075\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0655 - accuracy: 0.8231 - val_loss: 0.0699 - val_accuracy: 0.7963\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.0649 - accuracy: 0.8283 - val_loss: 0.0711 - val_accuracy: 0.8112\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0650 - accuracy: 0.8194 - val_loss: 0.0703 - val_accuracy: 0.8019\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0651 - accuracy: 0.8245 - val_loss: 0.0700 - val_accuracy: 0.7981\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0646 - accuracy: 0.8222 - val_loss: 0.0703 - val_accuracy: 0.8000\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0653 - accuracy: 0.8189 - val_loss: 0.0701 - val_accuracy: 0.8056\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0649 - accuracy: 0.8208 - val_loss: 0.0698 - val_accuracy: 0.8037\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0647 - accuracy: 0.8222 - val_loss: 0.0704 - val_accuracy: 0.8056\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0638 - accuracy: 0.8217 - val_loss: 0.0697 - val_accuracy: 0.8056\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0643 - accuracy: 0.8236 - val_loss: 0.0706 - val_accuracy: 0.7925\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0640 - accuracy: 0.8311 - val_loss: 0.0694 - val_accuracy: 0.8056\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0634 - accuracy: 0.8259 - val_loss: 0.0704 - val_accuracy: 0.8093\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0637 - accuracy: 0.8264 - val_loss: 0.0702 - val_accuracy: 0.8019\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0638 - accuracy: 0.8236 - val_loss: 0.0694 - val_accuracy: 0.7944\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0629 - accuracy: 0.8339 - val_loss: 0.0691 - val_accuracy: 0.8075\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0621 - accuracy: 0.8292 - val_loss: 0.0694 - val_accuracy: 0.8131\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0629 - accuracy: 0.8311 - val_loss: 0.0699 - val_accuracy: 0.8168\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0636 - accuracy: 0.8283 - val_loss: 0.0681 - val_accuracy: 0.8168\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0623 - accuracy: 0.8278 - val_loss: 0.0684 - val_accuracy: 0.8131\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0620 - accuracy: 0.8241 - val_loss: 0.0702 - val_accuracy: 0.8093\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0634 - accuracy: 0.8241 - val_loss: 0.0697 - val_accuracy: 0.8112\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0619 - accuracy: 0.8320 - val_loss: 0.0690 - val_accuracy: 0.8019\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0624 - accuracy: 0.8311 - val_loss: 0.0689 - val_accuracy: 0.8000\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0625 - accuracy: 0.8343 - val_loss: 0.0689 - val_accuracy: 0.8093\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0626 - accuracy: 0.8306 - val_loss: 0.0685 - val_accuracy: 0.8093\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0612 - accuracy: 0.8358 - val_loss: 0.0682 - val_accuracy: 0.8150\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0615 - accuracy: 0.8287 - val_loss: 0.0681 - val_accuracy: 0.8206\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0614 - accuracy: 0.8343 - val_loss: 0.0697 - val_accuracy: 0.8131\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0619 - accuracy: 0.8362 - val_loss: 0.0686 - val_accuracy: 0.8112\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0610 - accuracy: 0.8339 - val_loss: 0.0698 - val_accuracy: 0.8037\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0604 - accuracy: 0.8315 - val_loss: 0.0722 - val_accuracy: 0.8131\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0617 - accuracy: 0.8367 - val_loss: 0.0709 - val_accuracy: 0.8093\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0624 - accuracy: 0.8269 - val_loss: 0.0704 - val_accuracy: 0.8131\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0623 - accuracy: 0.8315 - val_loss: 0.0700 - val_accuracy: 0.8150\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0631 - accuracy: 0.8283 - val_loss: 0.0694 - val_accuracy: 0.8131\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0601 - accuracy: 0.8367 - val_loss: 0.0689 - val_accuracy: 0.8019\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0607 - accuracy: 0.8362 - val_loss: 0.0705 - val_accuracy: 0.7963\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0605 - accuracy: 0.8367 - val_loss: 0.0707 - val_accuracy: 0.7981\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0612 - accuracy: 0.8390 - val_loss: 0.0695 - val_accuracy: 0.8019\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0596 - accuracy: 0.8348 - val_loss: 0.0690 - val_accuracy: 0.8112\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0594 - accuracy: 0.8381 - val_loss: 0.0692 - val_accuracy: 0.8112\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0590 - accuracy: 0.8404 - val_loss: 0.0705 - val_accuracy: 0.8093\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0612 - accuracy: 0.8386 - val_loss: 0.0687 - val_accuracy: 0.8056\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0600 - accuracy: 0.8376 - val_loss: 0.0700 - val_accuracy: 0.8056\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0601 - accuracy: 0.8386 - val_loss: 0.0711 - val_accuracy: 0.8000\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0599 - accuracy: 0.8348 - val_loss: 0.0726 - val_accuracy: 0.8075\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0598 - accuracy: 0.8358 - val_loss: 0.0701 - val_accuracy: 0.8056\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0599 - accuracy: 0.8353 - val_loss: 0.0694 - val_accuracy: 0.8075\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0611 - accuracy: 0.8376 - val_loss: 0.0680 - val_accuracy: 0.8206\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0586 - accuracy: 0.8418 - val_loss: 0.0679 - val_accuracy: 0.8262\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0605 - accuracy: 0.8376 - val_loss: 0.0691 - val_accuracy: 0.8168\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0602 - accuracy: 0.8386 - val_loss: 0.0688 - val_accuracy: 0.8131\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0585 - accuracy: 0.8442 - val_loss: 0.0697 - val_accuracy: 0.8000\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0605 - accuracy: 0.8329 - val_loss: 0.0694 - val_accuracy: 0.8093\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0591 - accuracy: 0.8358 - val_loss: 0.0702 - val_accuracy: 0.8093\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0588 - accuracy: 0.8400 - val_loss: 0.0700 - val_accuracy: 0.8131\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0572 - accuracy: 0.8474 - val_loss: 0.0680 - val_accuracy: 0.8075\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0584 - accuracy: 0.8437 - val_loss: 0.0681 - val_accuracy: 0.8131\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0568 - accuracy: 0.8526 - val_loss: 0.0695 - val_accuracy: 0.8131\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0577 - accuracy: 0.8493 - val_loss: 0.0696 - val_accuracy: 0.8056\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0575 - accuracy: 0.8465 - val_loss: 0.0688 - val_accuracy: 0.8093\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0566 - accuracy: 0.8521 - val_loss: 0.0689 - val_accuracy: 0.8131\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0572 - accuracy: 0.8517 - val_loss: 0.0689 - val_accuracy: 0.8168\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0572 - accuracy: 0.8489 - val_loss: 0.0685 - val_accuracy: 0.8187\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0570 - accuracy: 0.8489 - val_loss: 0.0688 - val_accuracy: 0.8093\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0565 - accuracy: 0.8507 - val_loss: 0.0690 - val_accuracy: 0.8150\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f08f90106d0>"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO6sStOWZ_kQ",
        "outputId": "b7ff4bd8-8388-4a80-8049-77b960f873b4"
      },
      "source": [
        "prediction = model.predict(X_test)\n",
        "prediction1 = np.around(prediction,2)\n",
        "for i in prediction1:\n",
        "    print(i)"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.99]\n",
            "[0.89]\n",
            "[0.71]\n",
            "[0.99]\n",
            "[0.15]\n",
            "[0.16]\n",
            "[0.98]\n",
            "[0.99]\n",
            "[0.97]\n",
            "[0.32]\n",
            "[0.34]\n",
            "[0.26]\n",
            "[0.16]\n",
            "[0.45]\n",
            "[0.14]\n",
            "[0.]\n",
            "[0.77]\n",
            "[0.11]\n",
            "[0.07]\n",
            "[0.39]\n",
            "[0.15]\n",
            "[0.07]\n",
            "[0.4]\n",
            "[0.49]\n",
            "[0.86]\n",
            "[0.98]\n",
            "[0.15]\n",
            "[0.98]\n",
            "[0.97]\n",
            "[0.79]\n",
            "[0.65]\n",
            "[0.98]\n",
            "[0.12]\n",
            "[0.13]\n",
            "[0.94]\n",
            "[0.95]\n",
            "[0.12]\n",
            "[0.06]\n",
            "[0.23]\n",
            "[0.08]\n",
            "[0.99]\n",
            "[0.19]\n",
            "[0.08]\n",
            "[0.68]\n",
            "[0.16]\n",
            "[0.67]\n",
            "[0.22]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.08]\n",
            "[0.25]\n",
            "[0.]\n",
            "[0.07]\n",
            "[0.]\n",
            "[0.67]\n",
            "[0.09]\n",
            "[0.78]\n",
            "[0.58]\n",
            "[0.93]\n",
            "[0.65]\n",
            "[0.18]\n",
            "[0.73]\n",
            "[0.69]\n",
            "[0.31]\n",
            "[0.23]\n",
            "[0.87]\n",
            "[0.81]\n",
            "[0.2]\n",
            "[0.05]\n",
            "[0.68]\n",
            "[0.98]\n",
            "[0.01]\n",
            "[0.92]\n",
            "[0.2]\n",
            "[0.04]\n",
            "[0.91]\n",
            "[0.21]\n",
            "[0.2]\n",
            "[0.12]\n",
            "[0.94]\n",
            "[0.94]\n",
            "[0.23]\n",
            "[0.04]\n",
            "[0.98]\n",
            "[0.67]\n",
            "[0.95]\n",
            "[0.97]\n",
            "[0.7]\n",
            "[0.15]\n",
            "[0.06]\n",
            "[0.]\n",
            "[0.92]\n",
            "[0.14]\n",
            "[0.98]\n",
            "[0.94]\n",
            "[0.92]\n",
            "[0.2]\n",
            "[0.81]\n",
            "[0.98]\n",
            "[0.97]\n",
            "[0.98]\n",
            "[0.28]\n",
            "[0.1]\n",
            "[0.8]\n",
            "[0.23]\n",
            "[0.99]\n",
            "[0.91]\n",
            "[0.04]\n",
            "[0.]\n",
            "[0.31]\n",
            "[0.97]\n",
            "[0.09]\n",
            "[0.69]\n",
            "[0.81]\n",
            "[0.96]\n",
            "[0.9]\n",
            "[0.]\n",
            "[0.16]\n",
            "[0.95]\n",
            "[0.91]\n",
            "[0.62]\n",
            "[0.1]\n",
            "[0.98]\n",
            "[0.01]\n",
            "[0.34]\n",
            "[0.93]\n",
            "[0.1]\n",
            "[0.96]\n",
            "[0.97]\n",
            "[0.99]\n",
            "[0.07]\n",
            "[0.04]\n",
            "[0.06]\n",
            "[0.87]\n",
            "[0.94]\n",
            "[0.93]\n",
            "[0.13]\n",
            "[0.27]\n",
            "[0.04]\n",
            "[0.33]\n",
            "[0.07]\n",
            "[0.26]\n",
            "[0.45]\n",
            "[0.79]\n",
            "[0.21]\n",
            "[0.08]\n",
            "[0.54]\n",
            "[0.67]\n",
            "[0.1]\n",
            "[0.09]\n",
            "[0.97]\n",
            "[0.99]\n",
            "[0.05]\n",
            "[0.16]\n",
            "[0.92]\n",
            "[0.13]\n",
            "[0.75]\n",
            "[0.17]\n",
            "[0.2]\n",
            "[0.83]\n",
            "[0.1]\n",
            "[0.2]\n",
            "[0.13]\n",
            "[0.05]\n",
            "[0.1]\n",
            "[0.07]\n",
            "[0.]\n",
            "[0.05]\n",
            "[0.47]\n",
            "[0.57]\n",
            "[0.98]\n",
            "[0.38]\n",
            "[0.33]\n",
            "[0.97]\n",
            "[0.05]\n",
            "[0.69]\n",
            "[0.24]\n",
            "[0.08]\n",
            "[0.98]\n",
            "[0.06]\n",
            "[0.03]\n",
            "[0.99]\n",
            "[0.99]\n",
            "[0.7]\n",
            "[0.21]\n",
            "[0.86]\n",
            "[0.15]\n",
            "[0.57]\n",
            "[0.98]\n",
            "[0.91]\n",
            "[0.17]\n",
            "[0.]\n",
            "[0.94]\n",
            "[0.97]\n",
            "[0.98]\n",
            "[0.99]\n",
            "[0.76]\n",
            "[0.05]\n",
            "[0.23]\n",
            "[0.09]\n",
            "[0.06]\n",
            "[0.91]\n",
            "[0.87]\n",
            "[0.98]\n",
            "[0.99]\n",
            "[0.16]\n",
            "[0.88]\n",
            "[0.99]\n",
            "[0.97]\n",
            "[0.99]\n",
            "[0.19]\n",
            "[0.12]\n",
            "[0.94]\n",
            "[0.46]\n",
            "[0.29]\n",
            "[0.08]\n",
            "[0.33]\n",
            "[0.18]\n",
            "[0.03]\n",
            "[0.79]\n",
            "[0.01]\n",
            "[0.58]\n",
            "[0.8]\n",
            "[0.03]\n",
            "[0.96]\n",
            "[0.32]\n",
            "[0.99]\n",
            "[0.93]\n",
            "[0.9]\n",
            "[0.59]\n",
            "[0.99]\n",
            "[0.3]\n",
            "[0.97]\n",
            "[0.95]\n",
            "[0.12]\n",
            "[0.1]\n",
            "[0.99]\n",
            "[0.16]\n",
            "[0.08]\n",
            "[0.67]\n",
            "[0.18]\n",
            "[0.11]\n",
            "[0.26]\n",
            "[0.29]\n",
            "[0.11]\n",
            "[0.66]\n",
            "[0.07]\n",
            "[0.7]\n",
            "[0.99]\n",
            "[0.87]\n",
            "[0.94]\n",
            "[0.24]\n",
            "[0.34]\n",
            "[0.93]\n",
            "[0.19]\n",
            "[0.94]\n",
            "[0.05]\n",
            "[0.95]\n",
            "[0.92]\n",
            "[0.9]\n",
            "[0.98]\n",
            "[0.94]\n",
            "[0.34]\n",
            "[0.96]\n",
            "[0.04]\n",
            "[0.93]\n",
            "[0.09]\n",
            "[0.52]\n",
            "[0.95]\n",
            "[0.47]\n",
            "[0.7]\n",
            "[0.06]\n",
            "[0.96]\n",
            "[0.38]\n",
            "[0.1]\n",
            "[0.]\n",
            "[0.96]\n",
            "[0.64]\n",
            "[0.06]\n",
            "[0.48]\n",
            "[0.08]\n",
            "[0.08]\n",
            "[0.18]\n",
            "[0.07]\n",
            "[1.]\n",
            "[0.1]\n",
            "[0.26]\n",
            "[0.88]\n",
            "[0.06]\n",
            "[0.05]\n",
            "[0.83]\n",
            "[0.56]\n",
            "[0.07]\n",
            "[0.88]\n",
            "[0.97]\n",
            "[0.91]\n",
            "[0.07]\n",
            "[0.14]\n",
            "[0.14]\n",
            "[0.09]\n",
            "[0.1]\n",
            "[0.15]\n",
            "[0.98]\n",
            "[0.6]\n",
            "[0.01]\n",
            "[0.04]\n",
            "[0.08]\n",
            "[0.97]\n",
            "[0.96]\n",
            "[0.93]\n",
            "[0.93]\n",
            "[0.05]\n",
            "[0.83]\n",
            "[0.41]\n",
            "[0.05]\n",
            "[0.1]\n",
            "[0.26]\n",
            "[0.14]\n",
            "[0.07]\n",
            "[0.12]\n",
            "[0.99]\n",
            "[0.81]\n",
            "[0.01]\n",
            "[0.97]\n",
            "[0.48]\n",
            "[0.98]\n",
            "[0.15]\n",
            "[0.99]\n",
            "[0.09]\n",
            "[0.]\n",
            "[0.9]\n",
            "[0.14]\n",
            "[0.88]\n",
            "[0.61]\n",
            "[0.01]\n",
            "[0.26]\n",
            "[0.14]\n",
            "[0.89]\n",
            "[0.45]\n",
            "[0.3]\n",
            "[0.76]\n",
            "[0.05]\n",
            "[0.3]\n",
            "[0.]\n",
            "[0.89]\n",
            "[0.08]\n",
            "[0.15]\n",
            "[0.06]\n",
            "[0.14]\n",
            "[0.15]\n",
            "[0.2]\n",
            "[0.16]\n",
            "[0.94]\n",
            "[0.98]\n",
            "[0.43]\n",
            "[0.68]\n",
            "[0.9]\n",
            "[0.74]\n",
            "[0.9]\n",
            "[0.]\n",
            "[0.98]\n",
            "[0.16]\n",
            "[0.93]\n",
            "[0.16]\n",
            "[0.15]\n",
            "[0.83]\n",
            "[0.81]\n",
            "[0.1]\n",
            "[0.95]\n",
            "[0.7]\n",
            "[0.08]\n",
            "[0.12]\n",
            "[0.98]\n",
            "[0.05]\n",
            "[0.15]\n",
            "[0.32]\n",
            "[0.97]\n",
            "[0.61]\n",
            "[0.79]\n",
            "[0.08]\n",
            "[0.44]\n",
            "[0.96]\n",
            "[0.07]\n",
            "[0.4]\n",
            "[0.01]\n",
            "[0.4]\n",
            "[0.96]\n",
            "[0.11]\n",
            "[0.05]\n",
            "[0.36]\n",
            "[0.22]\n",
            "[0.38]\n",
            "[0.16]\n",
            "[0.12]\n",
            "[0.03]\n",
            "[0.24]\n",
            "[0.05]\n",
            "[0.11]\n",
            "[0.34]\n",
            "[0.09]\n",
            "[0.79]\n",
            "[0.14]\n",
            "[0.91]\n",
            "[0.97]\n",
            "[0.09]\n",
            "[0.56]\n",
            "[0.34]\n",
            "[0.1]\n",
            "[0.89]\n",
            "[0.41]\n",
            "[0.22]\n",
            "[0.28]\n",
            "[0.97]\n",
            "[0.99]\n",
            "[0.89]\n",
            "[0.91]\n",
            "[0.08]\n",
            "[0.]\n",
            "[0.12]\n",
            "[0.78]\n",
            "[0.16]\n",
            "[0.8]\n",
            "[0.04]\n",
            "[0.74]\n",
            "[0.1]\n",
            "[0.03]\n",
            "[0.82]\n",
            "[0.95]\n",
            "[0.79]\n",
            "[0.]\n",
            "[0.27]\n",
            "[0.91]\n",
            "[0.14]\n",
            "[0.1]\n",
            "[0.76]\n",
            "[0.15]\n",
            "[0.98]\n",
            "[0.94]\n",
            "[0.15]\n",
            "[0.15]\n",
            "[0.13]\n",
            "[0.09]\n",
            "[0.03]\n",
            "[0.75]\n",
            "[0.98]\n",
            "[0.92]\n",
            "[0.03]\n",
            "[0.7]\n",
            "[0.35]\n",
            "[0.16]\n",
            "[0.05]\n",
            "[0.97]\n",
            "[0.16]\n",
            "[0.95]\n",
            "[0.21]\n",
            "[0.03]\n",
            "[0.4]\n",
            "[0.44]\n",
            "[0.99]\n",
            "[0.59]\n",
            "[0.24]\n",
            "[0.96]\n",
            "[0.76]\n",
            "[0.12]\n",
            "[0.22]\n",
            "[0.07]\n",
            "[0.1]\n",
            "[0.47]\n",
            "[0.28]\n",
            "[0.1]\n",
            "[0.28]\n",
            "[0.37]\n",
            "[0.99]\n",
            "[0.13]\n",
            "[0.12]\n",
            "[0.98]\n",
            "[0.87]\n",
            "[0.31]\n",
            "[0.1]\n",
            "[0.13]\n",
            "[0.01]\n",
            "[0.39]\n",
            "[0.99]\n",
            "[0.69]\n",
            "[0.17]\n",
            "[0.96]\n",
            "[0.05]\n",
            "[0.82]\n",
            "[0.98]\n",
            "[0.]\n",
            "[0.92]\n",
            "[0.14]\n",
            "[0.98]\n",
            "[0.81]\n",
            "[0.13]\n",
            "[0.03]\n",
            "[0.84]\n",
            "[0.19]\n",
            "[0.88]\n",
            "[0.96]\n",
            "[0.05]\n",
            "[0.96]\n",
            "[0.31]\n",
            "[0.81]\n",
            "[0.3]\n",
            "[0.99]\n",
            "[0.96]\n",
            "[0.15]\n",
            "[0.04]\n",
            "[0.21]\n",
            "[0.97]\n",
            "[0.11]\n",
            "[0.98]\n",
            "[0.22]\n",
            "[0.28]\n",
            "[0.09]\n",
            "[0.09]\n",
            "[0.15]\n",
            "[0.98]\n",
            "[0.07]\n",
            "[0.53]\n",
            "[0.]\n",
            "[0.11]\n",
            "[0.73]\n",
            "[0.68]\n",
            "[0.99]\n",
            "[0.]\n",
            "[0.23]\n",
            "[0.09]\n",
            "[0.96]\n",
            "[0.8]\n",
            "[0.05]\n",
            "[0.]\n",
            "[0.47]\n",
            "[0.15]\n",
            "[0.8]\n",
            "[0.25]\n",
            "[0.01]\n",
            "[0.94]\n",
            "[0.78]\n",
            "[0.06]\n",
            "[0.09]\n",
            "[0.99]\n",
            "[0.53]\n",
            "[0.71]\n",
            "[0.06]\n",
            "[0.07]\n",
            "[0.86]\n",
            "[0.95]\n",
            "[0.22]\n",
            "[0.55]\n",
            "[0.97]\n",
            "[0.09]\n",
            "[0.15]\n",
            "[0.96]\n",
            "[0.91]\n",
            "[0.11]\n",
            "[0.08]\n",
            "[0.]\n",
            "[0.21]\n",
            "[0.13]\n",
            "[0.85]\n",
            "[0.04]\n",
            "[0.38]\n",
            "[0.24]\n",
            "[0.75]\n",
            "[0.1]\n",
            "[0.97]\n",
            "[0.07]\n",
            "[0.15]\n",
            "[0.99]\n",
            "[0.03]\n",
            "[0.03]\n",
            "[0.24]\n",
            "[0.97]\n",
            "[0.12]\n",
            "[0.6]\n",
            "[0.87]\n",
            "[0.]\n",
            "[0.83]\n",
            "[0.08]\n",
            "[0.]\n",
            "[0.25]\n",
            "[0.94]\n",
            "[0.04]\n",
            "[0.05]\n",
            "[0.01]\n",
            "[0.96]\n",
            "[0.04]\n",
            "[0.09]\n",
            "[0.25]\n",
            "[0.39]\n",
            "[0.46]\n",
            "[0.03]\n",
            "[0.4]\n",
            "[0.22]\n",
            "[0.04]\n",
            "[0.79]\n",
            "[0.12]\n",
            "[0.91]\n",
            "[0.31]\n",
            "[0.79]\n",
            "[0.94]\n",
            "[0.98]\n",
            "[0.19]\n",
            "[0.71]\n",
            "[0.1]\n",
            "[0.19]\n",
            "[0.15]\n",
            "[0.1]\n",
            "[0.28]\n",
            "[0.83]\n",
            "[0.25]\n",
            "[0.37]\n",
            "[0.14]\n",
            "[0.]\n",
            "[0.03]\n",
            "[0.04]\n",
            "[0.21]\n",
            "[0.13]\n",
            "[0.25]\n",
            "[0.01]\n",
            "[0.34]\n",
            "[0.12]\n",
            "[0.13]\n",
            "[0.25]\n",
            "[0.83]\n",
            "[0.24]\n",
            "[0.91]\n",
            "[0.06]\n",
            "[0.31]\n",
            "[0.38]\n",
            "[0.94]\n",
            "[0.81]\n",
            "[0.11]\n",
            "[0.08]\n",
            "[0.66]\n",
            "[0.01]\n",
            "[0.48]\n",
            "[0.1]\n",
            "[0.15]\n",
            "[0.17]\n",
            "[0.09]\n",
            "[0.18]\n",
            "[0.48]\n",
            "[0.16]\n",
            "[0.62]\n",
            "[0.07]\n",
            "[0.17]\n",
            "[0.13]\n",
            "[0.51]\n",
            "[0.05]\n",
            "[0.]\n",
            "[0.09]\n",
            "[0.13]\n",
            "[0.16]\n",
            "[0.93]\n",
            "[0.62]\n",
            "[0.6]\n",
            "[0.8]\n",
            "[0.07]\n",
            "[0.]\n",
            "[0.67]\n",
            "[0.14]\n",
            "[0.74]\n",
            "[0.95]\n",
            "[0.88]\n",
            "[0.13]\n",
            "[0.12]\n",
            "[0.13]\n",
            "[0.5]\n",
            "[0.44]\n",
            "[0.95]\n",
            "[0.18]\n",
            "[0.09]\n",
            "[0.97]\n",
            "[0.87]\n",
            "[0.2]\n",
            "[0.96]\n",
            "[0.99]\n",
            "[0.06]\n",
            "[0.03]\n",
            "[0.99]\n",
            "[0.39]\n",
            "[0.91]\n",
            "[0.09]\n",
            "[0.97]\n",
            "[0.59]\n",
            "[0.93]\n",
            "[0.88]\n",
            "[0.99]\n",
            "[0.23]\n",
            "[0.08]\n",
            "[0.08]\n",
            "[0.52]\n",
            "[0.03]\n",
            "[0.05]\n",
            "[0.06]\n",
            "[0.99]\n",
            "[0.07]\n",
            "[0.88]\n",
            "[0.47]\n",
            "[0.52]\n",
            "[0.1]\n",
            "[0.1]\n",
            "[0.]\n",
            "[0.05]\n",
            "[0.93]\n",
            "[0.99]\n",
            "[0.99]\n",
            "[0.51]\n",
            "[0.86]\n",
            "[0.15]\n",
            "[0.03]\n",
            "[0.97]\n",
            "[0.56]\n",
            "[0.91]\n",
            "[0.81]\n",
            "[0.13]\n",
            "[0.07]\n",
            "[0.81]\n",
            "[0.28]\n",
            "[0.21]\n",
            "[0.48]\n",
            "[0.05]\n",
            "[0.2]\n",
            "[0.45]\n",
            "[1.]\n",
            "[0.16]\n",
            "[0.1]\n",
            "[0.9]\n",
            "[0.74]\n",
            "[0.68]\n",
            "[0.35]\n",
            "[0.6]\n",
            "[0.27]\n",
            "[0.82]\n",
            "[0.93]\n",
            "[0.8]\n",
            "[0.47]\n",
            "[0.14]\n",
            "[0.99]\n",
            "[0.13]\n",
            "[0.12]\n",
            "[0.07]\n",
            "[0.12]\n",
            "[0.88]\n",
            "[0.89]\n",
            "[0.37]\n",
            "[0.06]\n",
            "[0.98]\n",
            "[0.23]\n",
            "[0.21]\n",
            "[0.7]\n",
            "[0.43]\n",
            "[0.88]\n",
            "[0.]\n",
            "[0.02]\n",
            "[0.15]\n",
            "[0.17]\n",
            "[0.09]\n",
            "[0.97]\n",
            "[0.12]\n",
            "[0.83]\n",
            "[0.97]\n",
            "[0.23]\n",
            "[0.13]\n",
            "[0.13]\n",
            "[0.09]\n",
            "[0.66]\n",
            "[0.83]\n",
            "[0.09]\n",
            "[0.99]\n",
            "[0.49]\n",
            "[0.05]\n",
            "[0.02]\n",
            "[0.98]\n",
            "[0.04]\n",
            "[0.28]\n",
            "[0.96]\n",
            "[0.35]\n",
            "[0.96]\n",
            "[0.98]\n",
            "[0.05]\n",
            "[0.99]\n",
            "[0.8]\n",
            "[0.65]\n",
            "[0.95]\n",
            "[0.94]\n",
            "[0.07]\n",
            "[0.3]\n",
            "[0.13]\n",
            "[0.08]\n",
            "[0.46]\n",
            "[0.1]\n",
            "[0.07]\n",
            "[0.9]\n",
            "[0.83]\n",
            "[0.09]\n",
            "[0.98]\n",
            "[0.13]\n",
            "[0.]\n",
            "[0.88]\n",
            "[0.1]\n",
            "[0.99]\n",
            "[0.99]\n",
            "[0.45]\n",
            "[0.97]\n",
            "[0.01]\n",
            "[0.23]\n",
            "[0.99]\n",
            "[0.14]\n",
            "[0.34]\n",
            "[0.43]\n",
            "[0.99]\n",
            "[0.14]\n",
            "[0.92]\n",
            "[0.18]\n",
            "[0.74]\n",
            "[0.07]\n",
            "[0.08]\n",
            "[0.05]\n",
            "[0.99]\n",
            "[0.05]\n",
            "[0.35]\n",
            "[0.66]\n",
            "[0.52]\n",
            "[0.02]\n",
            "[0.98]\n",
            "[0.2]\n",
            "[0.12]\n",
            "[0.26]\n",
            "[0.1]\n",
            "[0.11]\n",
            "[0.81]\n",
            "[0.12]\n",
            "[0.89]\n",
            "[0.28]\n",
            "[0.25]\n",
            "[0.23]\n",
            "[0.26]\n",
            "[0.46]\n",
            "[0.14]\n",
            "[0.98]\n",
            "[0.17]\n",
            "[0.61]\n",
            "[0.]\n",
            "[0.51]\n",
            "[0.14]\n",
            "[0.86]\n",
            "[0.11]\n",
            "[0.35]\n",
            "[0.97]\n",
            "[0.28]\n",
            "[0.02]\n",
            "[0.94]\n",
            "[0.42]\n",
            "[0.04]\n",
            "[0.39]\n",
            "[0.]\n",
            "[0.31]\n",
            "[0.29]\n",
            "[0.27]\n",
            "[0.02]\n",
            "[0.23]\n",
            "[0.24]\n",
            "[0.99]\n",
            "[0.01]\n",
            "[0.8]\n",
            "[0.71]\n",
            "[0.97]\n",
            "[0.13]\n",
            "[0.94]\n",
            "[0.01]\n",
            "[0.04]\n",
            "[0.92]\n",
            "[0.26]\n",
            "[0.98]\n",
            "[0.13]\n",
            "[0.29]\n",
            "[0.88]\n",
            "[0.1]\n",
            "[0.95]\n",
            "[0.92]\n",
            "[0.99]\n",
            "[0.09]\n",
            "[0.96]\n",
            "[0.24]\n",
            "[0.14]\n",
            "[0.99]\n",
            "[0.07]\n",
            "[0.88]\n",
            "[0.27]\n",
            "[0.96]\n",
            "[0.98]\n",
            "[0.]\n",
            "[0.14]\n",
            "[0.16]\n",
            "[0.07]\n",
            "[0.49]\n",
            "[0.11]\n",
            "[0.18]\n",
            "[0.22]\n",
            "[0.06]\n",
            "[0.08]\n",
            "[0.03]\n",
            "[0.14]\n",
            "[0.01]\n",
            "[0.03]\n",
            "[0.15]\n",
            "[0.07]\n",
            "[0.05]\n",
            "[0.08]\n",
            "[0.98]\n",
            "[0.1]\n",
            "[0.26]\n",
            "[0.98]\n",
            "[0.48]\n",
            "[0.88]\n",
            "[0.28]\n",
            "[0.12]\n",
            "[0.43]\n",
            "[0.44]\n",
            "[0.92]\n",
            "[0.]\n",
            "[0.91]\n",
            "[0.96]\n",
            "[0.19]\n",
            "[0.96]\n",
            "[0.25]\n",
            "[0.94]\n",
            "[0.]\n",
            "[0.06]\n",
            "[0.35]\n",
            "[0.96]\n",
            "[0.94]\n",
            "[0.96]\n",
            "[0.96]\n",
            "[0.2]\n",
            "[0.07]\n",
            "[0.74]\n",
            "[0.2]\n",
            "[0.93]\n",
            "[0.97]\n",
            "[0.47]\n",
            "[0.28]\n",
            "[0.89]\n",
            "[0.94]\n",
            "[0.25]\n",
            "[0.84]\n",
            "[0.99]\n",
            "[0.95]\n",
            "[0.91]\n",
            "[0.15]\n",
            "[0.07]\n",
            "[0.12]\n",
            "[0.11]\n",
            "[0.]\n",
            "[0.12]\n",
            "[0.29]\n",
            "[0.17]\n",
            "[0.3]\n",
            "[0.98]\n",
            "[0.2]\n",
            "[0.09]\n",
            "[0.62]\n",
            "[0.2]\n",
            "[0.37]\n",
            "[0.75]\n",
            "[0.06]\n",
            "[0.07]\n",
            "[0.91]\n",
            "[0.08]\n",
            "[0.15]\n",
            "[0.94]\n",
            "[0.78]\n",
            "[0.1]\n",
            "[0.96]\n",
            "[0.03]\n",
            "[0.88]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.97]\n",
            "[0.15]\n",
            "[0.95]\n",
            "[0.14]\n",
            "[0.95]\n",
            "[0.14]\n",
            "[0.11]\n",
            "[0.98]\n",
            "[0.13]\n",
            "[0.]\n",
            "[0.85]\n",
            "[0.86]\n",
            "[0.96]\n",
            "[0.17]\n",
            "[0.82]\n",
            "[0.34]\n",
            "[0.65]\n",
            "[0.23]\n",
            "[0.28]\n",
            "[0.22]\n",
            "[0.05]\n",
            "[0.25]\n",
            "[0.04]\n",
            "[0.95]\n",
            "[0.03]\n",
            "[0.98]\n",
            "[0.66]\n",
            "[0.1]\n",
            "[0.22]\n",
            "[0.96]\n",
            "[0.57]\n",
            "[0.1]\n",
            "[0.05]\n",
            "[0.93]\n",
            "[0.65]\n",
            "[0.04]\n",
            "[0.4]\n",
            "[0.08]\n",
            "[0.05]\n",
            "[0.03]\n",
            "[0.85]\n",
            "[0.13]\n",
            "[0.89]\n",
            "[0.2]\n",
            "[0.82]\n",
            "[0.07]\n",
            "[0.05]\n",
            "[0.24]\n",
            "[0.52]\n",
            "[0.95]\n",
            "[0.06]\n",
            "[0.98]\n",
            "[0.87]\n",
            "[0.08]\n",
            "[0.24]\n",
            "[0.94]\n",
            "[0.01]\n",
            "[0.86]\n",
            "[0.99]\n",
            "[0.73]\n",
            "[0.76]\n",
            "[0.08]\n",
            "[0.87]\n",
            "[0.9]\n",
            "[0.92]\n",
            "[0.98]\n",
            "[0.88]\n",
            "[0.96]\n",
            "[0.55]\n",
            "[0.]\n",
            "[0.26]\n",
            "[0.88]\n",
            "[0.91]\n",
            "[0.97]\n",
            "[0.15]\n",
            "[0.56]\n",
            "[0.15]\n",
            "[0.05]\n",
            "[0.47]\n",
            "[0.39]\n",
            "[0.48]\n",
            "[0.08]\n",
            "[0.08]\n",
            "[0.16]\n",
            "[0.94]\n",
            "[0.02]\n",
            "[0.24]\n",
            "[0.49]\n",
            "[0.33]\n",
            "[0.25]\n",
            "[0.05]\n",
            "[0.63]\n",
            "[0.8]\n",
            "[0.11]\n",
            "[0.98]\n",
            "[0.97]\n",
            "[0.]\n",
            "[0.09]\n",
            "[0.4]\n",
            "[0.76]\n",
            "[0.95]\n",
            "[0.15]\n",
            "[0.98]\n",
            "[0.78]\n",
            "[0.11]\n",
            "[0.09]\n",
            "[0.96]\n",
            "[0.87]\n",
            "[0.97]\n",
            "[0.14]\n",
            "[0.04]\n",
            "[0.23]\n",
            "[0.84]\n",
            "[0.94]\n",
            "[0.7]\n",
            "[0.71]\n",
            "[0.97]\n",
            "[0.]\n",
            "[0.94]\n",
            "[0.16]\n",
            "[0.29]\n",
            "[0.97]\n",
            "[0.55]\n",
            "[0.71]\n",
            "[0.52]\n",
            "[0.96]\n",
            "[0.12]\n",
            "[0.98]\n",
            "[0.24]\n",
            "[0.95]\n",
            "[0.97]\n",
            "[0.52]\n",
            "[0.25]\n",
            "[0.]\n",
            "[0.45]\n",
            "[0.43]\n",
            "[0.17]\n",
            "[0.]\n",
            "[0.98]\n",
            "[0.98]\n",
            "[0.04]\n",
            "[0.32]\n",
            "[0.03]\n",
            "[0.84]\n",
            "[0.05]\n",
            "[0.1]\n",
            "[0.1]\n",
            "[0.97]\n",
            "[0.99]\n",
            "[0.02]\n",
            "[0.99]\n",
            "[0.75]\n",
            "[0.99]\n",
            "[0.]\n",
            "[0.95]\n",
            "[0.08]\n",
            "[0.79]\n",
            "[0.59]\n",
            "[0.96]\n",
            "[0.99]\n",
            "[0.08]\n",
            "[0.98]\n",
            "[0.15]\n",
            "[0.5]\n",
            "[0.12]\n",
            "[0.04]\n",
            "[0.19]\n",
            "[0.05]\n",
            "[0.89]\n",
            "[0.39]\n",
            "[0.99]\n",
            "[0.18]\n",
            "[0.45]\n",
            "[0.23]\n",
            "[0.42]\n",
            "[0.16]\n",
            "[0.24]\n",
            "[0.]\n",
            "[0.32]\n",
            "[0.36]\n",
            "[0.07]\n",
            "[0.]\n",
            "[0.38]\n",
            "[0.24]\n",
            "[0.55]\n",
            "[0.05]\n",
            "[0.97]\n",
            "[0.19]\n",
            "[0.99]\n",
            "[0.31]\n",
            "[0.23]\n",
            "[0.]\n",
            "[0.39]\n",
            "[0.26]\n",
            "[0.]\n",
            "[0.97]\n",
            "[0.05]\n",
            "[0.94]\n",
            "[0.13]\n",
            "[0.56]\n",
            "[0.57]\n",
            "[0.98]\n",
            "[0.26]\n",
            "[0.]\n",
            "[0.96]\n",
            "[0.83]\n",
            "[0.05]\n",
            "[0.93]\n",
            "[0.92]\n",
            "[0.81]\n",
            "[0.06]\n",
            "[0.12]\n",
            "[0.42]\n",
            "[0.62]\n",
            "[0.85]\n",
            "[0.04]\n",
            "[0.25]\n",
            "[0.2]\n",
            "[0.05]\n",
            "[0.06]\n",
            "[0.37]\n",
            "[0.09]\n",
            "[0.78]\n",
            "[0.11]\n",
            "[0.24]\n",
            "[0.28]\n",
            "[0.94]\n",
            "[0.31]\n",
            "[0.94]\n",
            "[0.21]\n",
            "[0.45]\n",
            "[0.93]\n",
            "[0.28]\n",
            "[0.25]\n",
            "[0.85]\n",
            "[0.97]\n",
            "[0.18]\n",
            "[0.84]\n",
            "[0.31]\n",
            "[0.1]\n",
            "[0.98]\n",
            "[0.97]\n",
            "[0.12]\n",
            "[0.98]\n",
            "[0.79]\n",
            "[0.93]\n",
            "[0.88]\n",
            "[0.99]\n",
            "[0.98]\n",
            "[0.37]\n",
            "[0.87]\n",
            "[0.05]\n",
            "[0.07]\n",
            "[0.62]\n",
            "[0.]\n",
            "[0.23]\n",
            "[0.28]\n",
            "[0.88]\n",
            "[0.1]\n",
            "[0.1]\n",
            "[0.12]\n",
            "[0.99]\n",
            "[0.87]\n",
            "[0.88]\n",
            "[0.11]\n",
            "[0.87]\n",
            "[0.95]\n",
            "[0.94]\n",
            "[0.89]\n",
            "[0.98]\n",
            "[0.95]\n",
            "[0.87]\n",
            "[0.69]\n",
            "[0.01]\n",
            "[0.9]\n",
            "[0.1]\n",
            "[0.71]\n",
            "[0.45]\n",
            "[0.16]\n",
            "[0.14]\n",
            "[0.05]\n",
            "[0.09]\n",
            "[0.08]\n",
            "[0.61]\n",
            "[0.07]\n",
            "[0.76]\n",
            "[0.]\n",
            "[0.99]\n",
            "[0.34]\n",
            "[0.15]\n",
            "[0.27]\n",
            "[0.97]\n",
            "[0.97]\n",
            "[0.05]\n",
            "[0.99]\n",
            "[0.12]\n",
            "[0.08]\n",
            "[0.1]\n",
            "[0.18]\n",
            "[0.28]\n",
            "[0.78]\n",
            "[0.63]\n",
            "[0.49]\n",
            "[0.25]\n",
            "[0.59]\n",
            "[0.04]\n",
            "[0.29]\n",
            "[0.16]\n",
            "[0.34]\n",
            "[0.99]\n",
            "[0.99]\n",
            "[0.09]\n",
            "[0.94]\n",
            "[0.65]\n",
            "[0.99]\n",
            "[0.64]\n",
            "[0.89]\n",
            "[0.1]\n",
            "[0.79]\n",
            "[0.94]\n",
            "[0.94]\n",
            "[0.49]\n",
            "[0.09]\n",
            "[0.34]\n",
            "[0.95]\n",
            "[0.01]\n",
            "[0.74]\n",
            "[0.06]\n",
            "[0.99]\n",
            "[0.97]\n",
            "[0.06]\n",
            "[0.14]\n",
            "[0.97]\n",
            "[0.9]\n",
            "[0.94]\n",
            "[0.39]\n",
            "[0.14]\n",
            "[0.24]\n",
            "[0.21]\n",
            "[0.09]\n",
            "[0.24]\n",
            "[0.57]\n",
            "[0.37]\n",
            "[0.94]\n",
            "[0.52]\n",
            "[0.08]\n",
            "[0.99]\n",
            "[0.93]\n",
            "[0.]\n",
            "[0.95]\n",
            "[0.16]\n",
            "[0.09]\n",
            "[0.86]\n",
            "[0.96]\n",
            "[0.97]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sWaDbTow5gh",
        "outputId": "6ff95974-26a9-43e1-f17b-742c3d18b91d"
      },
      "source": [
        "accuracy_score(y_test, np.around(prediction))"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.831712789827973"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    }
  ]
}